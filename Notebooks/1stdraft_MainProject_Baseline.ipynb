{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "426b8f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# MSc Project: Biometric Security - Baseline Model\n",
    "# Author: Stella Williams\n",
    "# Date: 04.10.2025\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 1: Load Pretrained FaceNet Model\n",
    "# ----------------------------------------\n",
    "import torch\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random, os, io, cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "#use gpu if possible\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "#load pretained facenet model\n",
    "\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be364d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classes: ['Jose_Woldenberg', 'William_Hyde', 'Jose_Serra', 'Joseph_Hoy', 'Cecilia_Bolocco']\n"
     ]
    }
   ],
   "source": [
    "'''# Step 2: Load & Filter LFW Dataset (e.g. 5 identities)\n",
    "# Path to dataset\n",
    "lfw_path = '/Users/stel/Documents/Dissertation/msc-biometric-security/Datasets/lfw-dataset'\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load full dataset\n",
    "lfw_full = datasets.ImageFolder(root=lfw_path, transform=transform)\n",
    "\n",
    "# Pick 5 identities only (simulate SME-scale)\n",
    "target_classes = random.sample(lfw_full.classes, 5)\n",
    "print(\"Selected classes:\", target_classes)\n",
    "\n",
    "# Filter indices\n",
    "target_indices = [i for i, (_, label) in enumerate(lfw_full) if lfw_full.classes[label] in target_classes]\n",
    "lfw_subset = Subset(lfw_full, target_indices)\n",
    "# Define the loader\n",
    "lfw_loader = DataLoader(lfw_subset, batch_size=1, shuffle=True)\n",
    "'''\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 2: Load & Filter LFW Dataset (5 identities)\n",
    "# ----------------------------------------\n",
    "lfw_path = '/Users/stel/Documents/Dissertation/msc-biometric-security/Datasets/lfw-dataset'\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "# Load full dataset\n",
    "lfw_full = datasets.ImageFolder(root=lfw_path, transform=transform)\n",
    "target_classes = random.sample(lfw_full.classes, 5)\n",
    "print(\"Selected classes:\", target_classes)\n",
    "# Filter indices\n",
    "target_idx = [i for i, (_, lab) in enumerate(lfw_full) if lfw_full.classes[lab] in target_classes]\n",
    "lfw_subset = Subset(lfw_full, target_idx)\n",
    "# Define the loader\n",
    "lfw_loader = DataLoader(lfw_subset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c4074c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between clean and adversarial: 1.0000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Step 3: FGSM Attack\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# Loss and epsilon\n",
    "criterion = nn.CosineEmbeddingLoss()\n",
    "epsilon = 0.05\n",
    "\n",
    "def fgsm_attack(image, gradient, eps):\n",
    "    # Sign of gradient\n",
    "    sign = gradient.sign()\n",
    "    return torch.clamp(image + eps * sign, 0, 1)\n",
    "\n",
    "# Get a sample\n",
    "image, label = next(iter(lfw_loader))\n",
    "image, label = image.to(device), label.to(device)\n",
    "\n",
    "# Enable gradient\n",
    "image.requires_grad = True\n",
    "\n",
    "# Get embedding of true image\n",
    "embedding_orig = model(image)\n",
    "\n",
    "# Create \"true\" target for cosine loss (match itself)\n",
    "target = torch.tensor([1.0]).to(device)\n",
    "\n",
    "# Compute loss\n",
    "loss = criterion(embedding_orig, embedding_orig.detach(), target)\n",
    "model.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "# FGSM\n",
    "perturbed_image = fgsm_attack(image, image.grad.data, epsilon)\n",
    "\n",
    "# Evaluate perturbed embedding\n",
    "embedding_adv = model(perturbed_image)\n",
    "\n",
    "# Cosine similarity\n",
    "cos = nn.CosineSimilarity(dim=1)\n",
    "sim = cos(embedding_orig, embedding_adv).item()\n",
    "print(f\"Cosine similarity between clean and adversarial: {sim:.4f}\")'''\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 3: FGSM Attack\n",
    "# ----------------------------------------\n",
    "import torch.nn as nn\n",
    "# Loss and epsilon\n",
    "criterion = nn.CosineEmbeddingLoss()\n",
    "cos = nn.CosineSimilarity(dim=1)\n",
    "\n",
    "def fgsm_attack(image, grad, eps):\n",
    "    return torch.clamp(image + eps * grad.sign(), 0, 1)\n",
    "\n",
    "# Sample one image for display\n",
    "image, label = next(iter(lfw_loader))\n",
    "image, label = image.to(device), label.to(device)\n",
    "# Enable gradient\n",
    "image.requires_grad = True\n",
    "\n",
    "# Get embedding of true image\n",
    "embedding_orig = model(image)\n",
    "# Create \"true\" target for cosine loss (match itself)\n",
    "target = torch.tensor([1.0]).to(device)\n",
    "# Compute loss\n",
    "loss = criterion(embedding_orig, embedding_orig.detach(), target)\n",
    "model.zero_grad()\n",
    "loss.backward()\n",
    "# FGSM\n",
    "perturbed_image = fgsm_attack(image, image.grad.data, eps=0.05)\n",
    "# Evaluate perturbed embedding\n",
    "embedding_adv = model(perturbed_image)\n",
    "# Cosine similarity\n",
    "print(f\"FGSM cosine similarity: {cos(embedding_orig, embedding_adv).item():.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ba67d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perturbed_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m recovered\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Apply defence\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m jpeg_image \u001b[38;5;241m=\u001b[39m jpeg_defence(\u001b[43mperturbed_image\u001b[49m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Evaluate similarity again\u001b[39;00m\n\u001b[1;32m     22\u001b[0m embedding_jpeg \u001b[38;5;241m=\u001b[39m model(jpeg_image)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'perturbed_image' is not defined"
     ]
    }
   ],
   "source": [
    "'''# Step 4: Defence via JPEG Compression (Fixed)\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "def jpeg_defence(img_tensor, quality=50):\n",
    "    # Detach from computation graph\n",
    "    img_np = img_tensor.detach().squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "    img_np = (img_np * 255).astype(np.uint8)\n",
    "\n",
    "    # Save to JPEG in memory\n",
    "    _, encoded = cv2.imencode('.jpg', img_np, [int(cv2.IMWRITE_JPEG_QUALITY), quality])\n",
    "    decoded = cv2.imdecode(encoded, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Convert back to tensor\n",
    "    recovered = transforms.ToTensor()(Image.fromarray(cv2.cvtColor(decoded, cv2.COLOR_BGR2RGB)))\n",
    "    return recovered.unsqueeze(0).to(device)\n",
    "\n",
    "# Apply defence\n",
    "jpeg_image = jpeg_defence(perturbed_image)\n",
    "\n",
    "# Evaluate similarity again\n",
    "embedding_jpeg = model(jpeg_image)\n",
    "sim_defended = cos(embedding_orig, embedding_jpeg).item()\n",
    "print(f\"Cosine similarity (clean vs. JPEG-recovered): {sim_defended:.4f}\") '''\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 4: JPEG Defence\n",
    "# ----------------------------------------\n",
    "def jpeg_defence(img_tensor, quality=50):\n",
    "    # Detach from computation graph\n",
    "    img_np = img_tensor.detach().squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "    # Save to JPEG in memory\n",
    "    img_np = (img_np * 255).astype(np.uint8)\n",
    "    _, enc = cv2.imencode('.jpg', img_np, [int(cv2.IMWRITE_JPEG_QUALITY), quality])\n",
    "    dec = cv2.imdecode(enc, cv2.IMREAD_COLOR)\n",
    "    # Convert back to tensor\n",
    "    rec = transforms.ToTensor()(Image.fromarray(cv2.cvtColor(dec, cv2.COLOR_BGR2RGB)))\n",
    "    return rec.unsqueeze(0).to(device)\n",
    "# Apply defence\n",
    "jpeg_image = jpeg_defence(perturbed_image)\n",
    "# Evaluate similarity again\n",
    "embedding_jpeg = model(jpeg_image)\n",
    "print(f\"JPEG defence cosine similarity: {cos(embedding_orig, embedding_jpeg).item():.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e47aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Step 5: Visualise Images\n",
    "# ----------------------------------------\n",
    "def show_images(images, titles):\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(12, 4))\n",
    "    for ax, img, title in zip(axes, images, titles):\n",
    "        ax.imshow(img.detach().squeeze().permute(1, 2, 0).cpu())\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "show_images([image, perturbed_image, jpeg_image],\n",
    "            ['Original', 'FGSM Adversarial', 'JPEG Defence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50986d98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m similarities \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_samples), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBenchmarking FGSM + JPEG\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Get sample image\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     image, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(lfw_loader))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "'''# Step 6: Benchmark Loop â€“ FGSM + JPEG Defence Evaluation\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Parameters\n",
    "epsilon = 0.05\n",
    "num_samples = 30\n",
    "sim_threshold = 0.7  # if cosine similarity drops below this, identity is 'lost'\n",
    "\n",
    "# Results\n",
    "attack_success = 0\n",
    "jpeg_recovery = 0\n",
    "skipped = 0\n",
    "similarities = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for i in tqdm(range(num_samples), desc=\"Benchmarking FGSM + JPEG\"):\n",
    "\n",
    "    # Get sample image\n",
    "    image, label = next(iter(lfw_loader))\n",
    "    image, label = image.to(device), label.to(device)\n",
    "    image.requires_grad = True\n",
    "\n",
    "    # Embedding of clean image\n",
    "    embed_orig = model(image)\n",
    "\n",
    "    # Skip if model already fails\n",
    "    pred_clean = embed_orig.detach().cpu().numpy()\n",
    "    if np.linalg.norm(pred_clean) == 0:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    # Compute gradient\n",
    "    target = torch.tensor([1.0]).to(device)\n",
    "    loss = criterion(embed_orig, embed_orig.detach(), target)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # FGSM attack\n",
    "    perturbed = fgsm_attack(image, image.grad.data, epsilon)\n",
    "    embed_adv = model(perturbed)\n",
    "    \n",
    "    # Cosine similarity drop = attack success\n",
    "    sim_orig_adv = cos(embed_orig, embed_adv).item()\n",
    "    if sim_orig_adv < sim_threshold:\n",
    "        attack_success += 1\n",
    "\n",
    "    # Defence: JPEG\n",
    "    jpeg = jpeg_defence(perturbed)\n",
    "    embed_jpeg = model(jpeg)\n",
    "    sim_orig_jpeg = cos(embed_orig, embed_jpeg).item()\n",
    "\n",
    "    if sim_orig_jpeg >= sim_threshold:\n",
    "        jpeg_recovery += 1\n",
    "\n",
    "    similarities.append((sim_orig_adv, sim_orig_jpeg))\n",
    "\n",
    "# Results\n",
    "print(\"\\nðŸ“Š Benchmark Summary\")\n",
    "print(f\"Samples evaluated: {num_samples}\")\n",
    "print(f\"Skipped samples (no match): {skipped}\")\n",
    "print(f\"FGSM attack success rate: {attack_success / (num_samples - skipped):.2f}\")\n",
    "print(f\"JPEG defence recovery rate: {jpeg_recovery / (num_samples - skipped):.2f}\")\n",
    "'''\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 6: FGSM Benchmark Loop\n",
    "# ----------------------------------------\n",
    "# Parameters\n",
    "epsilons = [0.05, 0.1, 0.15, 0.3]\n",
    "print(\"\\n### FGSM Benchmark ###\")\n",
    "\n",
    "for eps in epsilons:\n",
    "    attack_success = 0; recovery_success = 0; total = 0\n",
    "    \n",
    "    for i in range(30):\n",
    "        img, lbl = next(iter(lfw_loader))\n",
    "        img, lbl = img.to(device), lbl.to(device)\n",
    "        img.requires_grad = True\n",
    "        \n",
    "        embed_orig = model(img)\n",
    "        target = torch.tensor([1.0]).to(device)\n",
    "        loss = criterion(embed_orig, embed_orig.detach(), target)\n",
    "        model.zero_grad(); loss.backward()\n",
    "        \n",
    "        adv = fgsm_attack(img, img.grad.data, eps)\n",
    "        embed_adv = model(adv)\n",
    "        sim_adv = cos(embed_orig, embed_adv).item()\n",
    "        \n",
    "        if sim_adv < 0.8: attack_success += 1\n",
    "        \n",
    "        jpeg = jpeg_defence(adv)\n",
    "        sim_jpeg = cos(embed_orig, model(jpeg)).item()\n",
    "        if sim_jpeg > 0.9: recovery_success += 1\n",
    "        \n",
    "        total += 1\n",
    "    \n",
    "    print(f\"Îµ={eps:.2f} | Attack Success: {attack_success/total:.2f} | JPEG Recovery: {recovery_success/total:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87892b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# âœ… Step 7: PGD Attack Function\n",
    "# ----------------------------------------\n",
    "def pgd_attack(model, image, epsilon=0.1, alpha=0.01, num_iter=10):\n",
    "    adv = image.clone().detach().to(device)\n",
    "    adv.requires_grad = True\n",
    "    \n",
    "    for _ in range(num_iter):\n",
    "        embed = model(adv)\n",
    "        target = torch.tensor([1.0]).to(device)\n",
    "        loss = criterion(embed, model(image).detach(), target)\n",
    "        model.zero_grad(); loss.backward()\n",
    "        grad = adv.grad.data\n",
    "        \n",
    "        adv = adv + alpha * grad.sign()\n",
    "        perturb = torch.clamp(adv - image, -epsilon, epsilon)\n",
    "        adv = torch.clamp(image + perturb, 0, 1).detach_()\n",
    "        adv.requires_grad = True\n",
    "        \n",
    "    return adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81a36075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### PGD Test ###\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lfw_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ----------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# âœ… Step 8: PGD Test Run\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ----------------------------------------\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m### PGD Test ###\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m img, lbl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mlfw_loader\u001b[49m))\n\u001b[1;32m      7\u001b[0m img, lbl \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mto(device), lbl\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m pert_pgd \u001b[38;5;241m=\u001b[39m pgd_attack(model, img, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, num_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lfw_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# âœ… Step 8: PGD Test Run\n",
    "# ----------------------------------------\n",
    "print(\"\\n### PGD Test ###\")\n",
    "\n",
    "img, lbl = next(iter(lfw_loader))\n",
    "img, lbl = img.to(device), lbl.to(device)\n",
    "\n",
    "pert_pgd = pgd_attack(model, img, epsilon=0.1, alpha=0.01, num_iter=20)\n",
    "sim_pgd = cos(model(img), model(pert_pgd)).item()\n",
    "print(f\"PGD cosine similarity: {sim_pgd:.4f}\")\n",
    "\n",
    "jpeg_pgd = jpeg_defence(pert_pgd)\n",
    "sim_pgd_jpeg = cos(model(img), model(jpeg_pgd)).item()\n",
    "print(f\"PGD + JPEG defence similarity: {sim_pgd_jpeg:.4f}\")\n",
    "\n",
    "show_images([img, pert_pgd, jpeg_pgd],\n",
    "            ['Original', 'PGD Attack', 'JPEG Defence (PGD)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8119efed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Testing FGSM with Îµ = 0.05\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lfw_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m):  \u001b[38;5;66;03m# 30 test samples\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     image, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mlfw_loader\u001b[49m))\n\u001b[1;32m     11\u001b[0m     image, label \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mto(device), label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m     image\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lfw_loader' is not defined"
     ]
    }
   ],
   "source": [
    "'''epsilons = [0.05, 0.1, 0.15, 0.3]\n",
    "\n",
    "for eps in epsilons:\n",
    "    print(f\"\\nðŸ“Œ Testing FGSM with Îµ = {eps}\")\n",
    "    attack_success = 0\n",
    "    recovery_success = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(30):  # 30 test samples\n",
    "        image, label = next(iter(lfw_loader))\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        image.requires_grad = True\n",
    "\n",
    "        # Original embedding and prediction\n",
    "        embed_orig = model(image)\n",
    "        pred_orig = embed_orig.argmax(dim=1) if embed_orig.dim() > 1 else None\n",
    "\n",
    "        # Generate adversarial example\n",
    "        target = torch.tensor([1.0]).to(device)\n",
    "        loss = criterion(embed_orig, embed_orig.detach(), target)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        adv_image = fgsm_attack(image, image.grad.data, eps)\n",
    "\n",
    "        # Evaluate adversarial\n",
    "        embed_adv = model(adv_image)\n",
    "        sim = cos(embed_orig, embed_adv).item()\n",
    "        if sim < 0.8:  # below threshold = attack success\n",
    "            attack_success += 1\n",
    "\n",
    "        # Apply JPEG\n",
    "        jpeg_image = jpeg_defence(adv_image)\n",
    "        embed_jpeg = model(jpeg_image)\n",
    "        sim_jpeg = cos(embed_orig, embed_jpeg).item()\n",
    "        if sim_jpeg > 0.9:  # above threshold = successful recovery\n",
    "            recovery_success += 1\n",
    "\n",
    "        total += 1\n",
    "\n",
    "    print(f\"FGSM Îµ={eps} â†’ Attack Success Rate: {attack_success/total:.2f}\")\n",
    "    print(f\"FGSM Îµ={eps} â†’ JPEG Recovery Rate: {recovery_success/total:.2f}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196549e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
