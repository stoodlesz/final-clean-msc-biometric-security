{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8004a900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "#Setup + Data Loading\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "\n",
    "# 1.2 Set seed and device\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 1.3 Dataset path\n",
    "lfw_path = \"../Datasets/lfw-dataset\"\n",
    "\n",
    "# 1.4 Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # For ResNet input\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 1.5 Load dataset\n",
    "lfw_dataset = datasets.ImageFolder(root=lfw_path, transform=transform)\n",
    "lfw_loader = DataLoader(lfw_dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54a41f18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/30 - Loss: 9.0540\n",
      "Batch 2/30 - Loss: 8.7226\n",
      "Batch 3/30 - Loss: 8.8491\n",
      "Batch 4/30 - Loss: 9.0044\n",
      "Batch 5/30 - Loss: 8.3634\n",
      "Batch 6/30 - Loss: 9.2350\n",
      "Batch 7/30 - Loss: 9.0577\n",
      "Batch 8/30 - Loss: 8.8550\n",
      "Batch 9/30 - Loss: 8.5327\n",
      "Batch 10/30 - Loss: 8.9819\n",
      "Batch 11/30 - Loss: 9.5624\n",
      "Batch 12/30 - Loss: 10.0737\n",
      "Batch 13/30 - Loss: 9.0845\n",
      "Batch 14/30 - Loss: 8.7513\n",
      "Batch 15/30 - Loss: 9.3882\n",
      "Batch 16/30 - Loss: 8.7689\n",
      "Batch 17/30 - Loss: 9.1567\n",
      "Batch 18/30 - Loss: 8.9601\n",
      "Batch 19/30 - Loss: 9.3708\n",
      "Batch 20/30 - Loss: 9.5732\n",
      "Batch 21/30 - Loss: 9.2405\n",
      "Batch 22/30 - Loss: 8.7530\n",
      "Batch 23/30 - Loss: 8.5632\n",
      "Batch 24/30 - Loss: 9.3274\n",
      "Batch 25/30 - Loss: 9.3998\n",
      "Batch 26/30 - Loss: 9.2444\n",
      "Batch 27/30 - Loss: 10.0054\n",
      "Batch 28/30 - Loss: 9.1901\n",
      "Batch 29/30 - Loss: 8.7757\n",
      "Batch 30/30 - Loss: 9.6213\n"
     ]
    }
   ],
   "source": [
    "#Define + Train ResNet (small batch for demo)\n",
    "\n",
    "model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "model.fc = nn.Linear(model.fc.in_features, len(lfw_dataset.classes))\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.train()\n",
    "for batch_idx, (images, labels) in enumerate(lfw_loader):\n",
    "    if batch_idx >= 30: break\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Batch {batch_idx+1}/30 - Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99635d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found correct prediction: George_W_Bush\n",
      "‚ùå Could not find a correctly classified image.\n"
     ]
    }
   ],
   "source": [
    "#FGSM Attack (loop until model gets one right)\n",
    "\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    perturbed = image + epsilon * sign_data_grad\n",
    "    return torch.clamp(perturbed, 0, 1)\n",
    "\n",
    "model.eval()\n",
    "image_found = False\n",
    "\n",
    "for _ in range(30):\n",
    "    image, label = next(iter(lfw_loader))\n",
    "    image = image[0].unsqueeze(0).to(device)\n",
    "    label = torch.tensor([label[0]]).to(device)\n",
    "    image.requires_grad = True\n",
    "\n",
    "    output = model(image)\n",
    "    init_pred = output.argmax(dim=1)\n",
    "\n",
    "    if init_pred.item() == label.item():\n",
    "        print(\"‚úÖ Found correct prediction:\", lfw_dataset.classes[init_pred.item()])\n",
    "        loss = criterion(output, label)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        data_grad = image.grad.data\n",
    "        epsilon = 0.1\n",
    "        perturbed_image = fgsm_attack(image, epsilon, data_grad)\n",
    "        clean_pred = init_pred.item()\n",
    "        break\n",
    "\n",
    "if not image_found:\n",
    "    print(\"‚ùå Could not find a correctly classified image.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5223b0d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perturbed_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     compressed_img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(buffer)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transforms\u001b[38;5;241m.\u001b[39mToTensor()(compressed_img)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 10\u001b[0m jpeg_image \u001b[38;5;241m=\u001b[39m jpeg_defence(\u001b[43mperturbed_image\u001b[49m)\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'perturbed_image' is not defined"
     ]
    }
   ],
   "source": [
    "#JPEG Defence\n",
    "def jpeg_defence(image_tensor, quality=30):\n",
    "    pil_img = transforms.ToPILImage()(image_tensor.squeeze().cpu())\n",
    "    buffer = io.BytesIO()\n",
    "    pil_img.save(buffer, format='JPEG', quality=quality)\n",
    "    buffer.seek(0)\n",
    "    compressed_img = Image.open(buffer)\n",
    "    return transforms.ToTensor()(compressed_img).unsqueeze(0).to(device)\n",
    "\n",
    "jpeg_image = jpeg_defence(perturbed_image)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    adv_out = model(perturbed_image)\n",
    "    jpeg_out = model(jpeg_image)\n",
    "\n",
    "adv_pred = adv_out.argmax(dim=1).item()\n",
    "jpeg_pred = jpeg_out.argmax(dim=1).item()\n",
    "\n",
    "print(f\"üéØ Clean Prediction: {lfw_dataset.classes[clean_pred]}\")\n",
    "print(f\"‚ö†Ô∏è  Adversarial Prediction: {lfw_dataset.classes[adv_pred]}\")\n",
    "print(f\"üîß JPEG Defence Prediction: {lfw_dataset.classes[jpeg_pred]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "159ff796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6815c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
