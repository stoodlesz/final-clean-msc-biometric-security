{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa234e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging utility\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "LOG_FILE = \"latent_experiment_log_190226.txt\"\n",
    "\n",
    "def log_message(message: str):\n",
    "    stamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    line = f\"[{stamp}] {message}\"\n",
    "    with open(LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(line + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bedcd203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Latent-Space Face Impersonation (Reduced-Compute Variant)\n",
    "# MSc Dissertation - Stella Williams\n",
    "# Inversion-free latent target synthesis experiment\n",
    "# Multi-run evaluation\n",
    "# This run is to get the plot working from file 2_latent_impersonation_stylegan-refactor_NO_INVERSION_Loop2. \n",
    "# --------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e011c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from facenet_pytorch import InceptionResnetV1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39a645b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\"Cell 2: Device, FaceNet setup\"\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Device configuration\n",
    "# --------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "# --------------------------------------------------------------\n",
    "# FaceNet embedding model (verification system)\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "facenet = InceptionResnetV1(pretrained=\"vggface2\").eval().to(device)\n",
    "# --------------------------------------------------------------\n",
    "# Preprocessing for FaceNet (160x160 input requirement)\n",
    "# --------------------------------------------------------------\n",
    "to_facenet = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def load_image(path):\n",
    "    return Image.open(path).convert(\"RGB\")\n",
    "\n",
    "def img_to_tensor(img):\n",
    "    return to_facenet(img).unsqueeze(0).to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def facenet_embed(img_tensor):\n",
    "    emb = facenet(img_tensor)\n",
    "    return nn.functional.normalize(emb, p=2, dim=1)\n",
    "\n",
    "def cosine(a, b):\n",
    "    return (a * b).sum(dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65b1dd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded StyleGAN2\n",
      "z_dim: 512\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Load pretrained StyleGAN2-ADA generator\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "sys.path.append(\"/Users/stel/Documents/Dissertation/msc-biometric-security-clean/stylegan2-ada-pytorch\")\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "STYLEGAN_REPO = \"/Users/stel/Documents/Dissertation/msc-biometric-security-clean/stylegan2-ada-pytorch\"\n",
    "STYLEGAN_PKL  = \"/Users/stel/Documents/Dissertation/msc-biometric-security-clean/Models/stylegan2-ffhq.pkl\"\n",
    "\n",
    "if STYLEGAN_REPO not in sys.path:\n",
    "    sys.path.append(STYLEGAN_REPO)\n",
    "\n",
    "with open(STYLEGAN_PKL, \"rb\") as f:\n",
    "    G = pickle.load(f)[\"G_ema\"].to(device).eval()\n",
    "\n",
    "print(\"Loaded StyleGAN2\")\n",
    "print(\"z_dim:\", G.z_dim)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c41ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Generator wrapper\n",
    "# Converts single w latent into w+ internally\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "def synth_from_w_single(w):\n",
    "    \"\"\"\n",
    "    Accepts either:\n",
    "    - w shape [1, w_dim]\n",
    "    - w shape [1, num_ws, w_dim] (w+)\n",
    "\n",
    "    Returns image in [0,1]\n",
    "    \"\"\"\n",
    "\n",
    "    if w.ndim == 2:\n",
    "        # w is [1, w_dim] â†’ broadcast to w+\n",
    "        w_plus = w.unsqueeze(1).repeat(1, G.synthesis.num_ws, 1)\n",
    "    elif w.ndim == 3:\n",
    "        # Already w+\n",
    "        w_plus = w\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected latent shape: {w.shape}\")\n",
    "\n",
    "    img = G.synthesis(w_plus, noise_mode=\"const\")\n",
    "    img = (img + 1) / 2\n",
    "    return img.clamp(0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dba9c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target embedding norm: 1.0\n",
      "Target embedding ready.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Load target identity (impersonation objective)\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "TARGET_A_PATH = \"/Users/stel/Documents/Dissertation/msc-biometric-security-clean/Datasets/lfw/Lenny_Kravitz/Lenny_Kravitz_0001.jpg\"\n",
    "TARGET_B_PATH = \"/Users/stel/Documents/Dissertation/msc-biometric-security-clean/Datasets/lfw/Patricia_Clarkson/Patricia_Clarkson_0001.jpg\"\n",
    "\n",
    "targetA_img = load_image(TARGET_A_PATH)\n",
    "targetB_img = load_image(TARGET_B_PATH)\n",
    "\n",
    "targetA_t = img_to_tensor(targetA_img)\n",
    "targetB_t = img_to_tensor(targetB_img)\n",
    "\n",
    "with torch.no_grad():\n",
    "    e_target = facenet_embed(targetA_t)\n",
    "    e_nontarget = facenet_embed(targetB_t)\n",
    "\n",
    "print(\"Target embedding norm:\", e_target.norm().item())\n",
    "\n",
    "# print(\"Initial w shape:\", w.shape)\n",
    "#inspecting the shape, it is likely [1, 1, w_dim], or [1, num_ws, w_dim] - with the latter meaning\n",
    "#we are alreadz in w+ space and the wrapper must not broadcast again. in my previous version, no loop,\n",
    "#i initialised w differently, mapping for from a random latent or mapping. dimensions changed.\n",
    "print(\"Target embedding ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6e515c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_message(\"--------------------------------------------------\")\n",
    "log_message(f\"Experiment started: {datetime.now()}\")\n",
    "log_message(\"Reduced-compute latent impersonation batch\")\n",
    "log_message(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82330cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef2af993",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_message' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m TARGET_SIM \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.85\u001b[39m\n\u001b[1;32m      8\u001b[0m LR \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.03\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mlog_message\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m log_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMulti-run 80-step max latent impersonation test version 2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m log_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_message' is not defined"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Multi-Run Latent Impersonation Experiment\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "NUM_RUNS = 5\n",
    "MAX_STEPS = 80\n",
    "TARGET_SIM = 0.85\n",
    "LR = 0.03\n",
    "\n",
    "log_message(\"--------------------------------------------------\")\n",
    "log_message(\"Multi-run 80-step max latent impersonation test version 2\")\n",
    "log_message(\"--------------------------------------------------\")\n",
    "\n",
    "\n",
    "results = []\n",
    "best_example = None\n",
    "\n",
    "print(\"\\nRunning latent impersonation batch...\\n\")\n",
    "print(\"NUM_RUNS =\", NUM_RUNS)\n",
    "\n",
    "for run in range(NUM_RUNS):\n",
    "\n",
    "    print(f\"\\n=== Run {run+1}/{NUM_RUNS} ===\")\n",
    "    log_message(f\"\\n=== Run {run+1}/{NUM_RUNS} ===\")\n",
    "\n",
    "    torch.manual_seed(run)\n",
    "\n",
    "    # Random z initialisation\n",
    "    z = torch.randn(1, G.z_dim, device=device)\n",
    "    with torch.no_grad():\n",
    "        w = G.mapping(z, None)\n",
    "\n",
    "    w = w.clone().detach().requires_grad_(True)\n",
    "    optimizer = optim.Adam([w], lr=LR)\n",
    "\n",
    "    start_time = time.time()\n",
    "    success = False\n",
    "\n",
    "    pbar = tqdm(range(MAX_STEPS), desc=f\"Run {run+1}\", leave=True)\n",
    "\n",
    "    for step in pbar:\n",
    "\n",
    "        img = synth_from_w_single(w)\n",
    "        img_160 = nn.functional.interpolate(\n",
    "            img, (160,160),\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        emb = facenet(img_160)\n",
    "        emb = nn.functional.normalize(emb, dim=1)\n",
    "\n",
    "        sim_target = cosine(emb, e_target)\n",
    "        sim_nontarget = cosine(emb, e_nontarget)\n",
    "\n",
    "        loss = 1 - sim_target.mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            \"cos_target\": f\"{sim_target.item():.4f}\",\n",
    "            \"cos_non_target\": f\"{sim_nontarget.item():.4f}\"\n",
    "        })\n",
    "\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            msg = (\n",
    "                f\"Run {run+1} | Step {step} | \"\n",
    "                f\"cos_target={sim_target.item():.4f} | \"\n",
    "                f\"cos_non_target={sim_nontarget.item():.4f}\"\n",
    "            )\n",
    "            print(msg)\n",
    "            log_message(msg)\n",
    "\n",
    "        if sim_target.item() >= TARGET_SIM:\n",
    "            success = True\n",
    "            best_example = img.detach().cpu()\n",
    "            break\n",
    "\n",
    "    runtime = time.time() - start_time\n",
    "\n",
    "    final_target = sim_target.item()\n",
    "    final_non_target = sim_nontarget.item()\n",
    "\n",
    "    summary = (\n",
    "        f\"Run {run+1} COMPLETE | \"\n",
    "        f\"Success={success} | \"\n",
    "        f\"Steps={step+1} | \"\n",
    "        f\"Final_target={final_target:.4f} | \"\n",
    "        f\"Final_non_target={final_non_target:.4f} | \"\n",
    "        f\"Runtime_sec={runtime:.2f}\"\n",
    "    )\n",
    "\n",
    "    print(summary)\n",
    "    log_message(summary)\n",
    "\n",
    "    results.append({\n",
    "        \"success\": success,\n",
    "        \"steps\": step + 1,\n",
    "        \"final_sim_target\": final_target,\n",
    "        \"final_sim_non_target\": final_non_target,\n",
    "        \"runtime_sec\": runtime\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1be8df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Batch Summary\n",
      "==============================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch Summary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==============================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mresults\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo runs completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\n==============================\")\n",
    "print(\"Batch Summary\")\n",
    "print(\"==============================\")\n",
    "\n",
    "if len(results) == 0:\n",
    "    print(\"No runs completed.\")\n",
    "else:\n",
    "    successes = [r for r in results if r[\"success\"]]\n",
    "    success_rate = len(successes) / len(results) * 100\n",
    "\n",
    "    print(f\"Total runs completed: {len(results)}\")\n",
    "    print(f\"Success rate: {success_rate:.1f}%\")\n",
    "\n",
    "    if len(successes) > 0:\n",
    "        mean_steps = np.mean([r[\"steps\"] for r in successes])\n",
    "        mean_target = np.mean([r[\"final_sim_target\"] for r in successes])\n",
    "    else:\n",
    "        mean_steps = 0\n",
    "        mean_target = 0\n",
    "\n",
    "    mean_non_target = np.mean([r[\"final_sim_non_target\"] for r in results])\n",
    "    mean_runtime = np.mean([r[\"runtime_sec\"] for r in results]) / 60\n",
    "\n",
    "    print(f\"Mean steps (successful only): {mean_steps:.2f}\")\n",
    "    print(f\"Mean final cosine (target): {mean_target:.4f}\")\n",
    "    print(f\"Mean cosine (non-target): {mean_non_target:.4f}\")\n",
    "    print(f\"Mean runtime: {mean_runtime:.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce08b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if best_example is not None:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(best_example.squeeze().permute(1,2,0))\n",
    "    plt.title(\"Example successful latent impersonation\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No successful run to visualise.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
