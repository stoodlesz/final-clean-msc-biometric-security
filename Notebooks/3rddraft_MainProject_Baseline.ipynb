{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "626fe692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# MSc Project – Biometric Security Baseline + Adversarial Testing\n",
    "# Author: Stella Williams\n",
    "# Draft 3\n",
    "# ==============================================================\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 1: Initialise Model & Device\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random, cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load pretrained FaceNet\n",
    "model = InceptionResnetV1(pretrained=\"vggface2\").eval().to(device)\n",
    "\n",
    "# Loss & similarity\n",
    "criterion = nn.CosineEmbeddingLoss()\n",
    "cos = nn.CosineSimilarity(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb9c2459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected identities: ['Alexandre_Daigle', 'Piotr_Anderszewski', 'Larry_Campbell', 'Francisco_Maturana', 'Carl_Levin']\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Step 2: Load and Filter LFW Dataset\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "lfw_path = \"/Users/stel/Documents/Dissertation/msc-biometric-security/Datasets/lfw-dataset\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "lfw_full = datasets.ImageFolder(root=lfw_path, transform=transform)\n",
    "target_classes = random.sample(lfw_full.classes, 5)\n",
    "print(\"Selected identities:\", target_classes)\n",
    "\n",
    "target_idx = [i for i, (_, label) in enumerate(lfw_full)\n",
    "              if lfw_full.classes[label] in target_classes]\n",
    "\n",
    "lfw_subset = Subset(lfw_full, target_idx)\n",
    "lfw_loader = DataLoader(lfw_subset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08d0800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Step 3: Attack and Defence Functions\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# --- FGSM ---\n",
    "def fgsm_attack(image, grad, eps):\n",
    "    return torch.clamp(image + eps * grad.sign(), 0, 1)\n",
    "\n",
    "# --- PGD (strong attacker) ---\n",
    "def pgd_attack(model, image, eps=0.4, alpha=0.02, steps=80):\n",
    "    adv = image.clone().detach().to(device)\n",
    "    adv.requires_grad = True\n",
    "\n",
    "    for _ in range(steps):\n",
    "        output = model(adv)\n",
    "        loss = criterion(output, model(image).detach(), torch.tensor([1.0]).to(device))\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        adv = adv + alpha * adv.grad.sign()\n",
    "        adv = torch.clamp(image + torch.clamp(adv - image, -eps, eps), 0, 1).detach()\n",
    "        adv.requires_grad = True\n",
    "\n",
    "    return adv\n",
    "\n",
    "# --- JPEG Defence ---\n",
    "def jpeg_defence(img_tensor, quality=35):\n",
    "    img_np = (img_tensor.detach().squeeze().permute(1,2,0).cpu().numpy()*255).astype(np.uint8)\n",
    "    _, enc = cv2.imencode(\".jpg\", img_np, [int(cv2.IMWRITE_JPEG_QUALITY), quality])\n",
    "    dec = cv2.imdecode(enc, cv2.IMREAD_COLOR)\n",
    "    rec = transforms.ToTensor()(Image.fromarray(cv2.cvtColor(dec, cv2.COLOR_BGR2RGB)))\n",
    "    return rec.unsqueeze(0).to(device)\n",
    "\n",
    "# --- Gaussian Blur ---\n",
    "def blur_defence(img_tensor, kernel=5):\n",
    "    img_np = (img_tensor.detach().squeeze().permute(1,2,0).cpu().numpy()*255).astype(np.uint8)\n",
    "    blurred = cv2.GaussianBlur(img_np, (kernel, kernel), 0)\n",
    "    rec = transforms.ToTensor()(Image.fromarray(cv2.cvtColor(blurred, cv2.COLOR_BGR2RGB)))\n",
    "    return rec.unsqueeze(0).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94026815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Step 4: Visualisation Helper\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "def show(img, title=\"Image\"):\n",
    "    plt.imshow(img.squeeze().permute(1,2,0).detach().cpu())\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "679f4893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### PGD Dual Evaluation ###\n",
      "Epsilon 0.05 | Self‑break: 0.00 | Impersonation Success: 0.20\n",
      "Epsilon 0.10 | Self‑break: 0.00 | Impersonation Success: 0.27\n",
      "Epsilon 0.20 | Self‑break: 0.00 | Impersonation Success: 0.07\n",
      "Epsilon 0.30 | Self‑break: 0.00 | Impersonation Success: 0.17\n",
      "Epsilon 0.40 | Self‑break: 0.00 | Impersonation Success: 0.13\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Step 5: PGD Benchmark (Self-attack + Impersonation Attack)\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "epsilons = [0.05, 0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "sim_threshold_self = 0.99     # model stops recognising you\n",
    "sim_threshold_imposter = 0.90 # model mistakenly thinks you're someone else\n",
    "\n",
    "print(\"\\n### PGD Dual Evaluation ###\")\n",
    "\n",
    "for eps in epsilons:\n",
    "    self_fail = 0\n",
    "    imposter_success = 0\n",
    "    total = 0\n",
    "\n",
    "    for _ in range(30):\n",
    "        img, _ = next(iter(lfw_loader))\n",
    "        img = img.to(device)\n",
    "        embed_orig = model(img)\n",
    "\n",
    "        # choose another random face to impersonate\n",
    "        imp_img, _ = next(iter(lfw_loader))\n",
    "        imp_img = imp_img.to(device)\n",
    "        embed_imp = model(imp_img)\n",
    "\n",
    "        # generate PGD adversarial\n",
    "        adv = pgd_attack(model, img, eps=eps, alpha=0.02, steps=60)\n",
    "\n",
    "        # SELF‑attack (does it stop matching itself?)\n",
    "        sim_self = cos(embed_orig, model(adv)).item()\n",
    "        if sim_self < sim_threshold_self: self_fail += 1\n",
    "\n",
    "        # IMPERSONATION (does adv resemble target person?)\n",
    "        sim_imp = cos(embed_imp, model(adv)).item()\n",
    "        if sim_imp > sim_threshold_imposter: imposter_success += 1\n",
    "\n",
    "        total += 1\n",
    "\n",
    "    print(f\"Epsilon {eps:.2f} | Self‑break: {self_fail/total:.2f} | Impersonation Success: {imposter_success/total:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd0cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
