# Project Log - 24 October 2025

## Summary
Continued development and testing of baseline adversarial robustness for facial recognition authentication.

Completed the benchmark testing of a pretrained FaceNet model under FGSM attacks with a JPEG compression defence. This marks a key step in simulating realistic attack-resilience workflows suitable for SMEs.

## Activities Completed
- Implemented the Fast Gradient Sign Method (FGSM) to test model vulnerability.  
- Evaluated how adversarial examples affect classification accuracy and cosine similarity in FaceNet.  
- Applied JPEG compression as a lightweight defensive strategy.  
- Tested defence effectiveness on perturbed images.  
- Logged prediction changes and similarity scores to measure FGSM and JPEG impacts.  
- Implemented and benchmarked FGSM (ε = 0.05) across 30 image samples from 5 facial identities.

Logged:

- Prediction accuracy before and after attack
- Cosine similarity between original and perturbed embeddings
- JPEG compression recovery performance

## Results

- ✅ FGSM Attack Success Rate: 0.00
- ✅ JPEG Defence Recovery Rate: 1.00
- FGSM at ε = 0.05 was not sufficient to break the pretrained FaceNet predictions.
- JPEG preprocessing retained prediction accuracy and feature similarity.

Deeper look:

**FGSM attack success rate** - The adversarial perturbations did **not succeed** in changing any predictions.                     
**JPEG defence recovery rate** - For every image tested, even if perturbed, the JPEG compression helped keep or restore the correct prediction.
**Skipped samples** 0 - All images were correctly classified by the model before attack – no filtering needed.      

## Key Takeaways

- Lightweight defences like JPEG compression may offer sufficient protection against weak attacks.
- Pretrained face recognition models demonstrate strong resilience at low perturbation levels.
- Higher attack strengths are needed to fully evaluate vulnerabilities and defence limits — especially for SMEs assessing trade-offs between usability and robustness.

## Next Objectives

- Increase FGSM strength to test system fragility at higher epsilon:
    - Try ε = 0.1, 0.15, 0.3

- Implement PGD (Projected Gradient Descent):
    - Multi-step, iterative attack
    - Harder to defend against than FGSM

- Compare performance metrics:
    - Cosine similarity
    - Attack success rate
    - Defence recovery (JPEG) 

## Reflection

This week’s focus was on understanding how, when, and why adversarial attacks actually work in practical systems — and what simple defences might work under constraints common in SMEs, such as limited computing power and lack of in-house AI expertise.
